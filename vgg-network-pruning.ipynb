{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchprofile 1>/dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-10T17:37:58.822491Z","iopub.execute_input":"2024-10-10T17:37:58.823437Z","iopub.status.idle":"2024-10-10T17:38:11.403166Z","shell.execute_reply.started":"2024-10-10T17:37:58.823394Z","shell.execute_reply":"2024-10-10T17:38:11.401811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nimport math\nimport random\nimport time\nfrom collections import OrderedDict, defaultdict\nfrom typing import Union, List\nimport numpy as np\nimport torch\nfrom matplotlib import pyplot as plt\nfrom torch import nn\nfrom torch.optim import *\nfrom torch.optim.lr_scheduler import *\nfrom torch.utils.data import DataLoader\nfrom torchprofile import profile_macs\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import Compose, RandomCrop, RandomHorizontalFlip, ToTensor\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:04:57.409076Z","iopub.execute_input":"2024-10-10T18:04:57.410048Z","iopub.status.idle":"2024-10-10T18:04:57.419680Z","shell.execute_reply.started":"2024-10-10T18:04:57.409989Z","shell.execute_reply":"2024-10-10T18:04:57.418418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:05:05.649677Z","iopub.execute_input":"2024-10-10T18:05:05.650449Z","iopub.status.idle":"2024-10-10T18:05:05.659506Z","shell.execute_reply.started":"2024-10-10T18:05:05.650400Z","shell.execute_reply":"2024-10-10T18:05:05.658331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n  model: nn.Module,\n  dataloader: DataLoader,\n  criterion: nn.Module,\n  optimizer: Optimizer,\n  scheduler: LambdaLR,\n  callbacks = None\n) -> None:\n  model.train()\n\n  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n    inputs = inputs.cuda()\n    targets = targets.cuda()\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n    scheduler.step()\n    if callbacks is not None:\n        for callback in callbacks:\n            callback()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:05:35.795670Z","iopub.execute_input":"2024-10-10T18:05:35.796125Z","iopub.status.idle":"2024-10-10T18:05:35.804197Z","shell.execute_reply.started":"2024-10-10T18:05:35.796038Z","shell.execute_reply":"2024-10-10T18:05:35.803125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef evaluate(\n  model: nn.Module,\n  dataloader: DataLoader,\n  verbose=True,\n) -> float:\n  model.eval()\n\n  num_samples = 0\n  num_correct = 0\n\n  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n                              disable=not verbose):\n    inputs = inputs.cuda()\n    targets = targets.cuda()\n    outputs = model(inputs)\n    outputs = outputs.argmax(dim=1)\n    num_samples += targets.size(0)\n    num_correct += (outputs == targets).sum()\n\n  return (num_correct / num_samples * 100).item()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T17:59:54.694948Z","iopub.execute_input":"2024-10-10T17:59:54.695401Z","iopub.status.idle":"2024-10-10T17:59:54.705146Z","shell.execute_reply.started":"2024-10-10T17:59:54.695357Z","shell.execute_reply":"2024-10-10T17:59:54.703748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def download_url(url, model_dir='.', overwrite=False):\n    import os, sys, ssl\n    from urllib.request import urlretrieve\n    ssl._create_default_https_context = ssl._create_unverified_context\n    target_dir = url.split('/')[-1]\n    model_dir = os.path.expanduser(model_dir)\n    try:\n        if not os.path.exists(model_dir):\n            os.makedirs(model_dir)\n        model_dir = os.path.join(model_dir, target_dir)\n        cached_file = model_dir\n        if not os.path.exists(cached_file) or overwrite:\n            sys.stderr.write('Downloading: \"{}\" to {}\\n'.format(url, cached_file))\n            urlretrieve(url, cached_file)\n        return cached_file\n    except Exception as e:\n       \n        os.remove(os.path.join(model_dir, 'download.lock'))\n        sys.stderr.write('Failed to download from url %s' % url + '\\n' + str(e) + '\\n')\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:00.332116Z","iopub.execute_input":"2024-10-10T18:06:00.332666Z","iopub.status.idle":"2024-10-10T18:06:00.345122Z","shell.execute_reply.started":"2024-10-10T18:06:00.332612Z","shell.execute_reply":"2024-10-10T18:06:00.343832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGG(nn.Module):\n  ARCH = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n\n  def __init__(self) -> None:\n    super().__init__()\n\n    layers = []\n    counts = defaultdict(int)\n\n    def add(name: str, layer: nn.Module) -> None:\n      layers.append((f\"{name}{counts[name]}\", layer))\n      counts[name] += 1\n\n    in_channels = 3\n    for x in self.ARCH:\n      if x != 'M':\n        # conv-bn-relu\n        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n        add(\"bn\", nn.BatchNorm2d(x))\n        add(\"relu\", nn.ReLU(True))\n        in_channels = x\n      else:\n        # maxpool\n        add(\"pool\", nn.MaxPool2d(2))\n\n    self.backbone = nn.Sequential(OrderedDict(layers))\n    self.classifier = nn.Linear(512, 10)\n\n  def forward(self, x: torch.Tensor) -> torch.Tensor:\n    # backbone: [N, 3, 32, 32] => [N, 512, 2, 2]\n    x = self.backbone(x)\n\n    # avgpool: [N, 512, 2, 2] => [N, 512]\n    x = x.mean([2, 3])\n\n    # classifier: [N, 512] => [N, 10]\n    x = self.classifier(x)\n    return x\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:02.371111Z","iopub.execute_input":"2024-10-10T18:06:02.371550Z","iopub.status.idle":"2024-10-10T18:06:02.384264Z","shell.execute_reply.started":"2024-10-10T18:06:02.371501Z","shell.execute_reply":"2024-10-10T18:06:02.382968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_url = \"/kaggle/working/vgg.cifar.pretrained.pth\"\ncheckpoint = torch.load(download_url(checkpoint_url), map_location=\"cpu\")\nmodel = VGG().cuda()\nprint(f\"=> loading checkpoint '{checkpoint_url}'\")\nmodel.load_state_dict(checkpoint['state_dict'])\nrecover_model = lambda: model.load_state_dict(checkpoint['state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:23.849584Z","iopub.execute_input":"2024-10-10T18:06:23.849981Z","iopub.status.idle":"2024-10-10T18:06:23.994725Z","shell.execute_reply.started":"2024-10-10T18:06:23.849941Z","shell.execute_reply":"2024-10-10T18:06:23.993708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_model_accuracy = evaluate(model, dataloader['test'])\ndense_model_size = get_model_size(model)\nprint(f\"dense model has accuracy={dense_model_accuracy:.2f}%\")\nprint(f\"dense model has size={dense_model_size/MiB:.2f} MiB\")","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:27.648730Z","iopub.execute_input":"2024-10-10T18:06:27.649537Z","iopub.status.idle":"2024-10-10T18:06:29.088571Z","shell.execute_reply.started":"2024-10-10T18:06:27.649494Z","shell.execute_reply":"2024-10-10T18:06:29.087170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_macs(model, inputs) -> int:\n    return profile_macs(model, inputs)\n\ndef get_sparsity(tensor: torch.Tensor) -> float:\n    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n\n\ndef get_model_sparsity(model: nn.Module) -> float:\n    num_nonzeros, num_elements = 0, 0\n    for param in model.parameters():\n        num_nonzeros += param.count_nonzero()\n        num_elements += param.numel()\n    return 1 - float(num_nonzeros) / num_elements\n\ndef get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n    num_counted_elements = 0\n    for param in model.parameters():\n        if count_nonzero_only:\n            num_counted_elements += param.count_nonzero()\n        else:\n            num_counted_elements += param.numel()\n    return num_counted_elements\n\n\ndef get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n    return get_num_parameters(model, count_nonzero_only) * data_width\n\nByte = 8\nKiB = 1024 * Byte\nMiB = 1024 * KiB\nGiB = 1024 * MiB","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:31.129831Z","iopub.execute_input":"2024-10-10T18:06:31.130295Z","iopub.status.idle":"2024-10-10T18:06:31.143047Z","shell.execute_reply.started":"2024-10-10T18:06:31.130250Z","shell.execute_reply":"2024-10-10T18:06:31.141789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fine_grained_prune(\n    test_tensor=torch.tensor([[-0.46, -0.40, 0.39, 0.19, 0.37],\n                              [0.00, 0.40, 0.17, -0.15, 0.16],\n                              [-0.20, -0.23, 0.36, 0.25, 0.03],\n                              [0.24, 0.41, 0.07, 0.13, -0.15],\n                              [0.48, -0.09, -0.36, 0.12, 0.45]]),\n    test_mask=torch.tensor([[True, True, False, False, False],\n                            [False, True, False, False, False],\n                            [False, False, False, False, False],\n                            [False, True, False, False, False],\n                            [True, False, False, False, True]]),\n    target_sparsity=0.75, target_nonzeros=None):\n    def plot_matrix(tensor, ax, title):\n        ax.imshow(tensor.cpu().numpy() == 0, vmin=0, vmax=1, cmap='tab20c')\n        ax.set_title(title)\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        for i in range(tensor.shape[1]):\n            for j in range(tensor.shape[0]):\n                text = ax.text(j, i, f'{tensor[i, j].item():.2f}',\n                                ha=\"center\", va=\"center\", color=\"k\")\n\n    test_tensor = test_tensor.clone()\n    fig, axes = plt.subplots(1,2, figsize=(6, 10))\n    ax_left, ax_right = axes.ravel()\n    plot_matrix(test_tensor, ax_left, 'dense tensor')\n\n    sparsity_before_pruning = get_sparsity(test_tensor)\n    mask = fine_grained_prune(test_tensor, target_sparsity)\n    sparsity_after_pruning = get_sparsity(test_tensor)\n    sparsity_of_mask = get_sparsity(mask)\n\n    plot_matrix(test_tensor, ax_right, 'sparse tensor')\n    fig.tight_layout()\n    plt.show()\n\n    print('* Test fine_grained_prune()')\n    print(f'target sparsity: {target_sparsity:.2f}')\n    print(f'sparsity before pruning: {sparsity_before_pruning:.2f}')\n    print(f'sparsity after pruning: {sparsity_after_pruning:.2f}')\n    print(f'sparsity of pruning mask: {sparsity_of_mask:.2f}')\n\n    if target_nonzeros is None:\n        if test_mask.equal(mask):\n            print('* Test passed.')\n        else:\n            print('* Test failed.')\n    else:\n        if mask.count_nonzero() == target_nonzeros:\n            print('* Test passed.')\n        else:\n            print('* Test failed.')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:35.242953Z","iopub.execute_input":"2024-10-10T18:06:35.243738Z","iopub.status.idle":"2024-10-10T18:06:45.276324Z","shell.execute_reply.started":"2024-10-10T18:06:35.243698Z","shell.execute_reply":"2024-10-10T18:06:45.275144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 32\ntransforms = {\n    \"train\": Compose([\n        RandomCrop(image_size, padding=4),\n        RandomHorizontalFlip(),\n        ToTensor(),\n    ]),\n    \"test\": ToTensor(),\n}\ndataset = {}\nfor split in [\"train\", \"test\"]:\n  dataset[split] = CIFAR10(\n    root=\"data/cifar10\",\n    train=(split == \"train\"),\n    download=True,\n    transform=transforms[split],\n  )\ndataloader = {}\nfor split in ['train', 'test']:\n  dataloader[split] = DataLoader(\n    dataset[split],\n    batch_size=512,\n    shuffle=(split == 'train'),\n    num_workers=0,\n    pin_memory=True,\n  )","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:45.280522Z","iopub.execute_input":"2024-10-10T18:06:45.281674Z","iopub.status.idle":"2024-10-10T18:06:47.107126Z","shell.execute_reply.started":"2024-10-10T18:06:45.281618Z","shell.execute_reply":"2024-10-10T18:06:47.106105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fine_grained_prune(tensor: torch.Tensor, sparsity : float) -> torch.Tensor:\n    sparsity = min(max(0.0, sparsity), 1.0)\n    if sparsity == 1.0:\n        tensor.zero_()\n        return torch.zeros_like(tensor)\n    elif sparsity == 0.0:\n        return torch.ones_like(tensor)\n\n    num_elements = tensor.numel()\n    num_zeros = round(num_elements * sparsity)\n    importance = torch.abs(tensor)\n    threshold = torch.kthvalue(importance.flatten(), num_zeros)[0]\n    mask = importance > threshold\n    tensor.mul_(mask)\n\n    return mask","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:47.108312Z","iopub.execute_input":"2024-10-10T18:06:47.108685Z","iopub.status.idle":"2024-10-10T18:06:47.116693Z","shell.execute_reply.started":"2024-10-10T18:06:47.108646Z","shell.execute_reply":"2024-10-10T18:06:47.115437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fine_grained_prune()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:47.118980Z","iopub.execute_input":"2024-10-10T18:06:47.119388Z","iopub.status.idle":"2024-10-10T18:06:47.727226Z","shell.execute_reply.started":"2024-10-10T18:06:47.119351Z","shell.execute_reply":"2024-10-10T18:06:47.726244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_sparsity = (15/25)\ntest_fine_grained_prune(target_sparsity=target_sparsity, target_nonzeros=10)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:06:53.088898Z","iopub.execute_input":"2024-10-10T18:06:53.089708Z","iopub.status.idle":"2024-10-10T18:06:53.656753Z","shell.execute_reply.started":"2024-10-10T18:06:53.089663Z","shell.execute_reply":"2024-10-10T18:06:53.655721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FineGrainedPruner:\n    def __init__(self, model, sparsity_dict):\n        self.masks = FineGrainedPruner.prune(model, sparsity_dict)\n\n    @torch.no_grad()\n    def apply(self, model):\n        for name, param in model.named_parameters():\n            if name in self.masks:\n                param *= self.masks[name]\n\n    @staticmethod\n    @torch.no_grad()\n    def prune(model, sparsity_dict):\n        masks = dict()\n        for name, param in model.named_parameters():\n            if param.dim() > 1: # we only prune conv and fc weights\n                masks[name] = fine_grained_prune(param, sparsity_dict[name])\n        return masks","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:07:01.609817Z","iopub.execute_input":"2024-10-10T18:07:01.610590Z","iopub.status.idle":"2024-10-10T18:07:01.618649Z","shell.execute_reply.started":"2024-10-10T18:07:01.610546Z","shell.execute_reply":"2024-10-10T18:07:01.617329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef sensitivity_scan(model, dataloader, scan_step=0.1, scan_start=0.4, scan_end=1.0, verbose=True):\n    sparsities = np.arange(start=scan_start, stop=scan_end, step=scan_step)\n    accuracies = []\n    named_conv_weights = [(name, param) for (name, param) \\\n                          in model.named_parameters() if param.dim() > 1]\n    for i_layer, (name, param) in enumerate(named_conv_weights):\n        param_clone = param.detach().clone()\n        accuracy = []\n        for sparsity in tqdm(sparsities, desc=f'scanning {i_layer}/{len(named_conv_weights)} weight - {name}'):\n            fine_grained_prune(param.detach(), sparsity=sparsity)\n            acc = evaluate(model, dataloader, verbose=False)\n            if verbose:\n                print(f'\\r    sparsity={sparsity:.2f}: accuracy={acc:.2f}%', end='')\n            # restore\n            param.copy_(param_clone)\n            accuracy.append(acc)\n        if verbose:\n            print(f'\\r    sparsity=[{\",\".join([\"{:.2f}\".format(x) for x in sparsities])}]: accuracy=[{\", \".join([\"{:.2f}%\".format(x) for x in accuracy])}]', end='')\n        accuracies.append(accuracy)\n    return sparsities, accuracies","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:07:03.850052Z","iopub.execute_input":"2024-10-10T18:07:03.850934Z","iopub.status.idle":"2024-10-10T18:07:03.863846Z","shell.execute_reply.started":"2024-10-10T18:07:03.850879Z","shell.execute_reply":"2024-10-10T18:07:03.862649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sparsities, accuracies = sensitivity_scan(\n    model, dataloader['test'], scan_step=0.1, scan_start=0.4, scan_end=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:07:13.942856Z","iopub.execute_input":"2024-10-10T18:07:13.943288Z","iopub.status.idle":"2024-10-10T18:08:29.399158Z","shell.execute_reply.started":"2024-10-10T18:07:13.943247Z","shell.execute_reply":"2024-10-10T18:08:29.398140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sensitivity_scan(sparsities, accuracies, dense_model_accuracy):\n    lower_bound_accuracy = 100 - (100 - dense_model_accuracy) * 1.5\n    fig, axes = plt.subplots(3, int(math.ceil(len(accuracies) / 3)),figsize=(15,8))\n    axes = axes.ravel()\n    plot_index = 0\n    for name, param in model.named_parameters():\n        if param.dim() > 1:\n            ax = axes[plot_index]\n            curve = ax.plot(sparsities, accuracies[plot_index])\n            line = ax.plot(sparsities, [lower_bound_accuracy] * len(sparsities))\n            ax.set_xticks(np.arange(start=0.4, stop=1.0, step=0.1))\n            ax.set_ylim(80, 95)\n            ax.set_title(name)\n            ax.set_xlabel('sparsity')\n            ax.set_ylabel('top-1 accuracy')\n            ax.legend([\n                'accuracy after pruning',\n                f'{lower_bound_accuracy / dense_model_accuracy * 100:.0f}% of dense model accuracy'\n            ])\n            ax.grid(axis='x')\n            plot_index += 1\n    fig.suptitle('Sensitivity Curves: Validation Accuracy vs. Pruning Sparsity')\n    fig.tight_layout()\n    fig.subplots_adjust(top=0.925)\n    plt.show()\n\nplot_sensitivity_scan(sparsities, accuracies, dense_model_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:08:29.401391Z","iopub.execute_input":"2024-10-10T18:08:29.402100Z","iopub.status.idle":"2024-10-10T18:08:31.614337Z","shell.execute_reply.started":"2024-10-10T18:08:29.402026Z","shell.execute_reply":"2024-10-10T18:08:31.613233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recover_model()\n\nsparsity_dict = {\n    'backbone.conv0.weight': 0,\n    'backbone.conv1.weight': 0,\n    'backbone.conv2.weight': 0.3,\n    'backbone.conv3.weight': 0.6,\n    'backbone.conv4.weight': 0.7,\n    'backbone.conv5.weight': 0.8,\n    'backbone.conv6.weight': 0.8,\n    'backbone.conv7.weight': 0.9,\n    'classifier.weight': 0\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:08:31.615751Z","iopub.execute_input":"2024-10-10T18:08:31.616196Z","iopub.status.idle":"2024-10-10T18:08:31.634572Z","shell.execute_reply.started":"2024-10-10T18:08:31.616147Z","shell.execute_reply":"2024-10-10T18:08:31.633741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pruner = FineGrainedPruner(model, sparsity_dict)\nprint(f'After pruning with sparsity dictionary')\nfor name, sparsity in sparsity_dict.items():\n    print(f'  {name}: {sparsity:.2f}')\nprint(f'The sparsity of each layer becomes')\nfor name, param in model.named_parameters():\n    if name in sparsity_dict:\n        print(f'  {name}: {get_sparsity(param):.2f}')\n\nsparse_model_size = get_model_size(model, count_nonzero_only=True)\nprint(f\"Sparse model has size={sparse_model_size / MiB:.2f} MiB = {sparse_model_size / dense_model_size * 100:.2f}% of dense model size\")\nsparse_model_accuracy = evaluate(model, dataloader['test'])\nprint(f\"Sparse model has accuracy={sparse_model_accuracy:.2f}% before fintuning\")\n\nplot_weight_distribution(model, count_nonzero_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:08:31.636306Z","iopub.execute_input":"2024-10-10T18:08:31.636643Z","iopub.status.idle":"2024-10-10T18:09:19.708104Z","shell.execute_reply.started":"2024-10-10T18:08:31.636611Z","shell.execute_reply":"2024-10-10T18:09:19.707036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_finetune_epochs = 5\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\ncriterion = nn.CrossEntropyLoss()\n\nbest_sparse_model_checkpoint = dict()\nbest_accuracy = 0\nprint(f'Finetuning Fine-grained Pruned Sparse Model')\nfor epoch in range(num_finetune_epochs):\n    train(model, dataloader['train'], criterion, optimizer, scheduler,\n          callbacks=[lambda: pruner.apply(model)])\n    accuracy = evaluate(model, dataloader['test'])\n    is_best = accuracy > best_accuracy\n    if is_best:\n        best_sparse_model_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n        best_accuracy = accuracy\n    print(f'    Epoch {epoch+1} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:09:19.709737Z","iopub.execute_input":"2024-10-10T18:09:19.710093Z","iopub.status.idle":"2024-10-10T18:10:50.638322Z","shell.execute_reply.started":"2024-10-10T18:09:19.710044Z","shell.execute_reply":"2024-10-10T18:10:50.637216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(best_sparse_model_checkpoint['state_dict'])\nsparse_model_size = get_model_size(model, count_nonzero_only=True)\nprint(f\"Sparse model has size={sparse_model_size / MiB:.2f} MiB = {sparse_model_size / dense_model_size * 100:.2f}% of dense model size\")\nsparse_model_accuracy = evaluate(model, dataloader['test'])\nprint(f\"Sparse model has accuracy={sparse_model_accuracy:.2f}% after fintuning\")","metadata":{"execution":{"iopub.status.busy":"2024-10-10T18:10:50.639787Z","iopub.execute_input":"2024-10-10T18:10:50.640174Z","iopub.status.idle":"2024-10-10T18:10:52.097226Z","shell.execute_reply.started":"2024-10-10T18:10:50.640135Z","shell.execute_reply":"2024-10-10T18:10:52.095990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}